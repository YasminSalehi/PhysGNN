{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6OLsMgB9xKr"
   },
   "source": [
    "# Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PzQa4nBFZv1"
   },
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOTkcxQ0QNI3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bfPS93SRxubn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.630721251885E12,
     "user_tz": 240.0,
     "elapsed": 7.0,
     "user": {
      "displayName": "Yasmin Salehi",
      "photoUrl": "",
      "userId": "17714471109892134283"
     }
    },
    "outputId": "ad395510-f2dc-4d5d-f8b7-8ca11cf9f636",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive\n"
     ]
    }
   ],
   "source": [
    "%cd drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hHaTCH1xz8v"
   },
   "outputs": [],
   "source": [
    "%cd PhysGNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkf9vx6lXom4"
   },
   "source": [
    "# Package Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DyY9b8dausZY"
   },
   "outputs": [],
   "source": [
    "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
    "!pip install tensorboardX\n",
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4O_TNMc91_d"
   },
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmkZgCfAcpvw"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "from random import shuffle\n",
    "import math\n",
    "import statistics\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "import datetime\n",
    "import pickle \n",
    "from joblib import dump, load\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU, GRU\n",
    "from torch_geometric.nn import JumpingKnowledge\n",
    "\n",
    "import torch_geometric as tg\n",
    "import torch_geometric.nn as tg_nn\n",
    "import torch_geometric.utils as tg_utils\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.nn import Sequential, JumpingKnowledge\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "from torch.nn import init\n",
    "import pdb\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "# For visualizing the results\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DS__GEdO-GCC"
   },
   "source": [
    "# Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veYEEy6_3rox"
   },
   "source": [
    "##Config 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9u8i0oHI3p2M"
   },
   "outputs": [],
   "source": [
    "# ----------------------------- Configuration 1 --------------------------------\n",
    "# -----------------------------                  --------------------------------\n",
    "class config1(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(config1, self).__init__()\n",
    "\n",
    "        self.conv1 = tg_nn.GraphConv(input_dim, hidden_dim, aggr='max')\n",
    "        self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv3 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv4 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv5 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv6 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "\n",
    "        self.jk1 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        self.jk2 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, 63)\n",
    "        self.lin2 = torch.nn.Linear(63, 3)\n",
    "        \n",
    "        self.active1 = nn.PReLU(hidden_dim)\n",
    "        self.active2 = nn.PReLU(hidden_dim)\n",
    "        self.active3 = nn.PReLU(hidden_dim)\n",
    "        self.active4 = nn.PReLU(hidden_dim)\n",
    "        self.active5 = nn.PReLU(hidden_dim)\n",
    "        self.active6 = nn.PReLU(hidden_dim)\n",
    "        self.active7 = nn.PReLU(63)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr ,data.batch\n",
    "        edge_weight = 1 / edge_weight\n",
    "        edge_weight = edge_weight.float()\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.active1(x)\n",
    "        xs = [x]\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.active2(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.active3(x)\n",
    "        xs += [x]\n",
    "\n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk1(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.active4(x)\n",
    "        xs = [x]\n",
    "       \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.active5(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x =self.conv6(x, edge_index)\n",
    "        x =  self.active6(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk2(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.active7(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "      \n",
    "        return (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum() \n",
    "\n",
    "        # return (pred - label).abs().sum()  #MAE\n",
    "        # return F.mse_loss(pred, label)  #MSE \n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSri18MsCs42"
   },
   "source": [
    "## Config2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7suXLvZmukk"
   },
   "outputs": [],
   "source": [
    "# ----------------------------- Configuration 2 --------------------------------\n",
    "# -----------------------------                  --------------------------------\n",
    "class config2(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(config2, self).__init__()\n",
    "\n",
    "        self.conv1 = tg_nn.GraphConv(input_dim, hidden_dim, aggr='add')\n",
    "        self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv3 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv4 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv5 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv6 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "\n",
    "        self.jk1 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        self.jk2 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, 63)\n",
    "        self.lin2 = torch.nn.Linear(63, 3)\n",
    "        \n",
    "        self.active1 = nn.PReLU(hidden_dim)\n",
    "        self.active2 = nn.PReLU(hidden_dim)\n",
    "        self.active3 = nn.PReLU(hidden_dim)\n",
    "        self.active4 = nn.PReLU(hidden_dim)\n",
    "        self.active5 = nn.PReLU(hidden_dim)\n",
    "        self.active6 = nn.PReLU(hidden_dim)\n",
    "        self.active7 = nn.PReLU(63)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr ,data.batch\n",
    "        edge_weight = 1 / edge_weight\n",
    "        edge_weight = edge_weight.float()\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.active1(x)\n",
    "        xs = [x]\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.active2(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.active3(x)\n",
    "        xs += [x]\n",
    "\n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk1(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.active4(x)\n",
    "        xs = [x]\n",
    "       \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.active5(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x =self.conv6(x, edge_index)\n",
    "        x =  self.active6(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk2(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.active7(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "      \n",
    "        return (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum() \n",
    "\n",
    "        # return (pred - label).abs().sum()  #MAE\n",
    "        # return F.mse_loss(pred, label)  #MSE \n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Rat5cGP0_29"
   },
   "source": [
    "##Config3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smGZ7Kma0_NB"
   },
   "outputs": [],
   "source": [
    "# ----------------------------- Configuration 3 ---------------------------------\n",
    "# -----------------------------                  --------------------------------\n",
    "class config3(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(config3, self).__init__()\n",
    "\n",
    "        self.conv1 = tg_nn.GraphConv(input_dim, hidden_dim, aggr='add')\n",
    "        self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv3 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv4 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv5 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv6 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "\n",
    "        self.jk1 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        self.jk2 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, 63)\n",
    "        self.lin2 = torch.nn.Linear(63, 3)\n",
    "        \n",
    "        self.active1 = nn.PReLU(hidden_dim)\n",
    "        self.active2 = nn.PReLU(hidden_dim)\n",
    "        self.active3 = nn.PReLU(hidden_dim)\n",
    "        self.active4 = nn.PReLU(hidden_dim)\n",
    "        self.active5 = nn.PReLU(hidden_dim)\n",
    "        self.active6 = nn.PReLU(hidden_dim)\n",
    "        self.active7 = nn.PReLU(63)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr ,data.batch\n",
    "        edge_weight = 1 / edge_weight\n",
    "        edge_weight = edge_weight.float()\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.active1(x)\n",
    "        xs = [x]\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.active2(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.active3(x)\n",
    "        xs += [x]\n",
    "\n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk1(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.active4(x)\n",
    "        xs = [x]\n",
    "       \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.active5(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x =self.conv6(x, edge_index)\n",
    "        x =  self.active6(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk2(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.active7(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "      \n",
    "        return (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum() \n",
    "\n",
    "        # return (pred - label).abs().sum()  #MAE\n",
    "        # return F.mse_loss(pred, label)  #MSE \n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTeiUT57usRK"
   },
   "source": [
    "##Config4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PP-T2p1LuvTC"
   },
   "outputs": [],
   "source": [
    "# ----------------------------- Configuration 4 --------------------------------\n",
    "# -----------------------------                  --------------------------------\n",
    "class config4(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(config4, self).__init__()\n",
    "\n",
    "        self.conv1 = tg_nn.GraphConv(input_dim, hidden_dim, aggr='add')\n",
    "        self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv3 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv4 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv5 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv6 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "\n",
    "        self.jk1 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        self.jk2 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, 63)\n",
    "        self.lin2 = torch.nn.Linear(63, 3)\n",
    "        \n",
    "        self.active1 = nn.PReLU(hidden_dim)\n",
    "        self.active2 = nn.PReLU(hidden_dim)\n",
    "        self.active3 = nn.PReLU(hidden_dim)\n",
    "        self.active4 = nn.PReLU(hidden_dim)\n",
    "        self.active5 = nn.PReLU(hidden_dim)\n",
    "        self.active6 = nn.PReLU(hidden_dim)\n",
    "        self.active7 = nn.PReLU(63)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr ,data.batch\n",
    "        edge_weight = 1 / edge_weight\n",
    "        edge_weight = edge_weight.float()\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.active1(x)\n",
    "        xs = [x]\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.active2(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.active3(x)\n",
    "        xs += [x]\n",
    "\n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk1(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.active4(x)\n",
    "        xs = [x]\n",
    "       \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.active5(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x =self.conv6(x, edge_index)\n",
    "        x =  self.active6(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk2(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.active7(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "      \n",
    "        return (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum() \n",
    "\n",
    "        # return (pred - label).abs().sum()  #MAE\n",
    "        # return F.mse_loss(pred, label)  #MSE \n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDbu1I22uwGW"
   },
   "source": [
    "##Config5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfYhodxyux-u"
   },
   "outputs": [],
   "source": [
    "# ----------------------------- Configuration 5 --------------------------------\n",
    "# -----------------------------                  --------------------------------\n",
    "class config5(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(config5, self).__init__()\n",
    "\n",
    "        self.conv1 = tg_nn.GraphConv(input_dim, hidden_dim, aggr='add')\n",
    "        self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv3 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv4 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv5 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv6 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "\n",
    "        self.jk1 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        self.jk2 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, 63)\n",
    "        self.lin2 = torch.nn.Linear(63, 3)\n",
    "        \n",
    "        self.active1 = nn.PReLU(hidden_dim)\n",
    "        self.active2 = nn.PReLU(hidden_dim)\n",
    "        self.active3 = nn.PReLU(hidden_dim)\n",
    "        self.active4 = nn.PReLU(hidden_dim)\n",
    "        self.active5 = nn.PReLU(hidden_dim)\n",
    "        self.active6 = nn.PReLU(hidden_dim)\n",
    "        self.active7 = nn.PReLU(63)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr ,data.batch\n",
    "        edge_weight = 1 / edge_weight\n",
    "        edge_weight = edge_weight.float()\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.active1(x)\n",
    "        xs = [x]\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.active2(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.active3(x)\n",
    "        xs += [x]\n",
    "\n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk1(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.active4(x)\n",
    "        xs = [x]\n",
    "       \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.active5(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x =self.conv6(x, edge_index)\n",
    "        x =  self.active6(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk2(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.active7(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "      \n",
    "        return (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum() \n",
    "\n",
    "        # return (pred - label).abs().sum()  #MAE\n",
    "        # return F.mse_loss(pred, label)  #MSE \n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pd-rZrCb6ju0"
   },
   "source": [
    "##Config 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K797FTfs6kC1"
   },
   "outputs": [],
   "source": [
    "# ----------------------------- Configuration 6 --------------------------------\n",
    "# -----------------------------                  --------------------------------\n",
    "class config6(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(config6, self).__init__()\n",
    "\n",
    "        self.conv1 = tg_nn.GraphConv(input_dim, hidden_dim, aggr='add')\n",
    "        self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv3 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv4 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv5 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv6 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "\n",
    "        self.jk1 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        self.jk2 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, 63)\n",
    "        self.lin2 = torch.nn.Linear(63, 3)\n",
    "        \n",
    "        self.active1 = nn.PReLU(hidden_dim)\n",
    "        self.active2 = nn.PReLU(hidden_dim)\n",
    "        self.active3 = nn.PReLU(hidden_dim)\n",
    "        self.active4 = nn.PReLU(hidden_dim)\n",
    "        self.active5 = nn.PReLU(hidden_dim)\n",
    "        self.active6 = nn.PReLU(hidden_dim)\n",
    "        self.active7 = nn.PReLU(63)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr ,data.batch\n",
    "        edge_weight = 1 / edge_weight\n",
    "        edge_weight = edge_weight.float()\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.active1(x)\n",
    "        xs = [x]\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.active2(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.active3(x)\n",
    "        xs += [x]\n",
    "\n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk1(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.active4(x)\n",
    "        xs = [x]\n",
    "       \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.active5(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x =self.conv6(x, edge_index)\n",
    "        x =  self.active6(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk2(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.active7(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "      \n",
    "        return (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum() \n",
    "\n",
    "        # return (pred - label).abs().sum()  #MAE\n",
    "        # return F.mse_loss(pred, label)  #MSE \n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMZmrFkWoGnk"
   },
   "source": [
    "##Config 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tXoic9YoJ_O"
   },
   "outputs": [],
   "source": [
    "# ----------------------------- Configuration 7 --------------------------------\n",
    "# -----------------------------                  --------------------------------\n",
    "class config7(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(config7, self).__init__()\n",
    "\n",
    "        self.conv1 = tg_nn.GraphConv(input_dim, hidden_dim, aggr='add')\n",
    "        self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv3 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv4 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv5 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        self.conv6 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='add')\n",
    "\n",
    "        self.jk1 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        self.jk2 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, 63)\n",
    "        self.lin2 = torch.nn.Linear(63, 3)\n",
    "        \n",
    "        self.active1 = nn.PReLU(hidden_dim)\n",
    "        self.active2 = nn.PReLU(hidden_dim)\n",
    "        self.active3 = nn.PReLU(hidden_dim)\n",
    "        self.active4 = nn.PReLU(hidden_dim)\n",
    "        self.active5 = nn.PReLU(hidden_dim)\n",
    "        self.active6 = nn.PReLU(hidden_dim)\n",
    "        self.active7 = nn.PReLU(63)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr ,data.batch\n",
    "        edge_weight = 1 / edge_weight\n",
    "        edge_weight = edge_weight.float()\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.active1(x)\n",
    "        xs = [x]\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.active2(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.active3(x)\n",
    "        xs += [x]\n",
    "\n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk1(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.active4(x)\n",
    "        xs = [x]\n",
    "       \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.active5(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x =self.conv6(x, edge_index)\n",
    "        x =  self.active6(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk2(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.active7(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "      \n",
    "        return (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum() \n",
    "\n",
    "        # return (pred - label).abs().sum()  #MAE\n",
    "        # return F.mse_loss(pred, label)  #MSE \n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8lngNjPu1AP"
   },
   "source": [
    "##Config8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Xyb77S1u3Sl"
   },
   "outputs": [],
   "source": [
    "# ----------------------------- Configuration 8 --------------------------------\n",
    "# -----------------------------                  --------------------------------\n",
    "class config8(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(config8, self).__init__()\n",
    "\n",
    "        self.conv1 = tg_nn.GraphConv(input_dim, hidden_dim, aggr='add')\n",
    "        \n",
    "        if dataset_name == 'dataset_1':\n",
    "            self.conv2 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')  \n",
    "        else:\n",
    "            self.conv2 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='add')\n",
    "            \n",
    "        self.conv3 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv4 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv5 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv6 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "\n",
    "        self.jk1 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        self.jk2 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, 63)\n",
    "        self.lin2 = torch.nn.Linear(63, 3)\n",
    "        \n",
    "        self.active1 = nn.PReLU(hidden_dim)\n",
    "        self.active2 = nn.PReLU(hidden_dim)\n",
    "        self.active3 = nn.PReLU(hidden_dim)\n",
    "        self.active4 = nn.PReLU(hidden_dim)\n",
    "        self.active5 = nn.PReLU(hidden_dim)\n",
    "        self.active6 = nn.PReLU(hidden_dim)\n",
    "        self.active7 = nn.PReLU(63)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr ,data.batch\n",
    "        edge_weight = 1 / edge_weight\n",
    "        edge_weight = edge_weight.float()\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.active1(x)\n",
    "        xs = [x]\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.active2(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.active3(x)\n",
    "        xs += [x]\n",
    "\n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk1(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.active4(x)\n",
    "        xs = [x]\n",
    "       \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.active5(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x =self.conv6(x, edge_index)\n",
    "        x =  self.active6(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk2(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.active7(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "      \n",
    "        return (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum() \n",
    "\n",
    "        # return (pred - label).abs().sum()  #MAE\n",
    "        # return F.mse_loss(pred, label)  #MSE \n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72eIcafFxDiJ"
   },
   "source": [
    "##Config9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQXZdlMnxGOw"
   },
   "outputs": [],
   "source": [
    "# ----------------------------- Configuration 9 --------------------------------\n",
    "# -----------------------------                  --------------------------------\n",
    "class config9(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(config9, self).__init__()\n",
    "\n",
    "        self.conv1 = tg_nn.GraphConv(input_dim, hidden_dim, aggr='add')\n",
    "\n",
    "        if dataset_name == 'dataset_1':\n",
    "            self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')   \n",
    "        else:\n",
    "            self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='add')\n",
    "            \n",
    "        self.conv3 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv4 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv5 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv6 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "\n",
    "        self.jk1 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        self.jk2 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, 63)\n",
    "        self.lin2 = torch.nn.Linear(63, 3)\n",
    "        \n",
    "        self.active1 = nn.PReLU(hidden_dim)\n",
    "        self.active2 = nn.PReLU(hidden_dim)\n",
    "        self.active3 = nn.PReLU(hidden_dim)\n",
    "        self.active4 = nn.PReLU(hidden_dim)\n",
    "        self.active5 = nn.PReLU(hidden_dim)\n",
    "        self.active6 = nn.PReLU(hidden_dim)\n",
    "        self.active7 = nn.PReLU(63)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr ,data.batch\n",
    "        edge_weight = 1 / edge_weight\n",
    "        edge_weight = edge_weight.float()\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.active1(x)\n",
    "        xs = [x]\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.active2(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.active3(x)\n",
    "        xs += [x]\n",
    "\n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk1(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.active4(x)\n",
    "        xs = [x]\n",
    "       \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.active5(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x =self.conv6(x, edge_index)\n",
    "        x =  self.active6(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk2(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.active7(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "      \n",
    "        return (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum() \n",
    "\n",
    "        # return (pred - label).abs().sum()  #MAE\n",
    "        # return F.mse_loss(pred, label)  #MSE \n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSxokzXS6vHq"
   },
   "source": [
    "##Config 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WwQfxxgU6x2E"
   },
   "outputs": [],
   "source": [
    "# ----------------------------- Configuration 10 --------------------------------\n",
    "# -----------------------------                  --------------------------------\n",
    "class config10(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(config10, self).__init__()\n",
    "\n",
    "        self.conv1 = tg_nn.GraphConv(input_dim, hidden_dim, aggr='add')\n",
    "\n",
    "        if dataset_name == 'dataset_1':       \n",
    "            self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        else:\n",
    "            self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='add')\n",
    "              \n",
    "        self.conv3 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv4 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv5 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv6 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "\n",
    "        self.jk1 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        self.jk2 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, 63)\n",
    "        self.lin2 = torch.nn.Linear(63, 3)\n",
    "        \n",
    "        self.active1 = nn.PReLU(hidden_dim)\n",
    "        self.active2 = nn.PReLU(hidden_dim)\n",
    "        self.active3 = nn.PReLU(hidden_dim)\n",
    "        self.active4 = nn.PReLU(hidden_dim)\n",
    "        self.active5 = nn.PReLU(hidden_dim)\n",
    "        self.active6 = nn.PReLU(hidden_dim)\n",
    "        self.active7 = nn.PReLU(63)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr ,data.batch\n",
    "        edge_weight = 1 / edge_weight\n",
    "        edge_weight = edge_weight.float()\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.active1(x)\n",
    "        xs = [x]\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.active2(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.active3(x)\n",
    "        xs += [x]\n",
    "\n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk1(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.conv4(x, edge_index, edge_weight)\n",
    "        x = self.active4(x)\n",
    "        xs = [x]\n",
    "       \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.active5(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x =self.conv6(x, edge_index)\n",
    "        x =  self.active6(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk2(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.active7(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "      \n",
    "        return (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum() \n",
    "\n",
    "        # return (pred - label).abs().sum()  #MAE\n",
    "        # return F.mse_loss(pred, label)  #MSE \n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xqi-n78r6-YO"
   },
   "source": [
    "##Config 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8SdZfNO6_4M"
   },
   "outputs": [],
   "source": [
    "# ----------------------------- Configuration 11 --------------------------------\n",
    "# -----------------------------                  --------------------------------\n",
    "class config11(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(config11, self).__init__()\n",
    "\n",
    "        self.conv1 = tg_nn.GraphConv(input_dim, hidden_dim, aggr='add')\n",
    "\n",
    "        if dataset_name == 'dataset_1':\n",
    "            self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')    \n",
    "        else:\n",
    "            self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='add')\n",
    "        \n",
    "        self.conv3 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv4 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv5 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv6 = tg_nn.SAGEConv(hidden_dim, hidden_dim, aggr='max')\n",
    "\n",
    "        self.jk1 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        self.jk2 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, 63)\n",
    "        self.lin2 = torch.nn.Linear(63, 3)\n",
    "        \n",
    "        self.active1 = nn.PReLU(hidden_dim)\n",
    "        self.active2 = nn.PReLU(hidden_dim)\n",
    "        self.active3 = nn.PReLU(hidden_dim)\n",
    "        self.active4 = nn.PReLU(hidden_dim)\n",
    "        self.active5 = nn.PReLU(hidden_dim)\n",
    "        self.active6 = nn.PReLU(hidden_dim)\n",
    "        self.active7 = nn.PReLU(63)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr ,data.batch\n",
    "        edge_weight = 1 / edge_weight\n",
    "        edge_weight = edge_weight.float()\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.active1(x)\n",
    "        xs = [x]\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.active2(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.active3(x)\n",
    "        xs += [x]\n",
    "\n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk1(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.conv4(x, edge_index, edge_weight)\n",
    "        x = self.active4(x)\n",
    "        xs = [x]\n",
    "       \n",
    "        x = self.conv5(x, edge_index, edge_weight)\n",
    "        x = self.active5(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x =self.conv6(x, edge_index)\n",
    "        x =  self.active6(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk2(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.active7(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "      \n",
    "        return (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum() \n",
    "\n",
    "        # return (pred - label).abs().sum()  #MAE\n",
    "        # return F.mse_loss(pred, label)  #MSE \n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6cnuzY_7FF2"
   },
   "source": [
    "##Config 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6n8TY5Wg7GgR"
   },
   "outputs": [],
   "source": [
    "# ----------------------------- Configuration 12 --------------------------------\n",
    "# -----------------------------                  --------------------------------\n",
    "class config12(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(config12, self).__init__()\n",
    "\n",
    "        self.conv1 = tg_nn.GraphConv(input_dim, hidden_dim, aggr='add')\n",
    "\n",
    "        if dataset_name == 'dataset_1':\n",
    "            self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')        \n",
    "        else:\n",
    "            self.conv2 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='add')\n",
    "            \n",
    "        self.conv3 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv4 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv5 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "        self.conv6 = tg_nn.GraphConv(hidden_dim, hidden_dim, aggr='max')\n",
    "\n",
    "        self.jk1 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        self.jk2 = JumpingKnowledge(\"lstm\", hidden_dim, 3)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, 63)\n",
    "        self.lin2 = torch.nn.Linear(63, 3)\n",
    "        \n",
    "        self.active1 = nn.PReLU(hidden_dim)\n",
    "        self.active2 = nn.PReLU(hidden_dim)\n",
    "        self.active3 = nn.PReLU(hidden_dim)\n",
    "        self.active4 = nn.PReLU(hidden_dim)\n",
    "        self.active5 = nn.PReLU(hidden_dim)\n",
    "        self.active6 = nn.PReLU(hidden_dim)\n",
    "        self.active7 = nn.PReLU(63)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr ,data.batch\n",
    "        edge_weight = 1 / edge_weight\n",
    "        edge_weight = edge_weight.float()\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.active1(x)\n",
    "        xs = [x]\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.active2(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.active3(x)\n",
    "        xs += [x]\n",
    "\n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk1(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.conv4(x, edge_index, edge_weight)\n",
    "        x = self.active4(x)\n",
    "        xs = [x]\n",
    "       \n",
    "        x = self.conv5(x, edge_index, edge_weight)\n",
    "        x = self.active5(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        x =self.conv6(x, edge_index, edge_weight)\n",
    "        x =  self.active6(x)\n",
    "        xs += [x]\n",
    "        \n",
    "        # ~~~~~~~~~~~~Jumping knowledge applied ~~~~~~~~~~~~~~~\n",
    "        x = self.jk2(xs)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.active7(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "      \n",
    "        return (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum() \n",
    "\n",
    "        # return (pred - label).abs().sum()  #MAE\n",
    "        # return F.mse_loss(pred, label)  #MSE \n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1JkAplM-Ry_"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3UKmjB6PAgK"
   },
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "def early_stopping(val_loss, current_min):\n",
    "    stop = False\n",
    "    if val_loss[-1] > current_min:\n",
    "        stop = True\n",
    "    return stop\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "# Training \n",
    "def train(dataset, writer, dataset_name, config_selected):\n",
    "\n",
    "    data_size = len(dataset)\n",
    "    print(dataset_name)\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "    if dataset_name == 'dataset_1':\n",
    "        print('Dataset 1 is being used.')\n",
    "        loader = DataLoader(dataset[:int(data_size * 0.7)], batch_size=4, shuffle=True)\n",
    "        validation_loader = DataLoader(dataset[int(data_size * 0.7): int(data_size * 0.9)], batch_size=1, shuffle=False)\n",
    "        test_loader = DataLoader(dataset[int(data_size * 0.9):], batch_size=1, shuffle=False)\n",
    "    else:\n",
    "        print('Dataset 2 is being used.')\n",
    "        loader = DataLoader(dataset[:int(data_size * 0.7)], batch_size=8, shuffle=True)\n",
    "        validation_loader = DataLoader(dataset[int(data_size * 0.7): int(data_size * 0.9)], batch_size=1, shuffle=False)\n",
    "        test_loader = DataLoader(dataset[int(data_size * 0.9):], batch_size=1, shuffle=False)      \n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "    # MODIFICATION #1 Build the Model\n",
    "    if config_selected == 'config1':\n",
    "        model = config1(7, 112, 3)\n",
    "        print('Configuration 1 is selected.')\n",
    "    elif config_selected == 'config2':  \n",
    "        model = config2(7, 112, 3)\n",
    "        print('Configuration 2 is selected.')\n",
    "    elif config_selected == 'config3':   \n",
    "        model = config3(7, 112, 3)\n",
    "        print('Configuration 3 is selected.')\n",
    "    elif config_selected == 'config4':   \n",
    "        model = config4(7, 112, 3)\n",
    "        print('Configuration 4 is selected.')\n",
    "    elif config_selected == 'config5':  \n",
    "        model = config5(7, 112, 3) \n",
    "        print('Configuration 5 is selected.')\n",
    "    elif config_selected == 'config6': \n",
    "        model = config6(7, 112, 3) \n",
    "        print('Configuration 6 is selected.')\n",
    "    elif config_selected == 'config7': \n",
    "        model = config7(7, 112, 3)\n",
    "        print('Configuration 7 is selected.')\n",
    "    elif config_selected == 'config8':  \n",
    "        model = config8(7, 112, 3)\n",
    "        print('Configuration 8 is selected.') \n",
    "    elif config_selected == 'config9': \n",
    "        model = config9(7, 112, 3)\n",
    "        print('Configuration 9 is selected.')\n",
    "    elif config_selected == 'config10': \n",
    "        model = config10(7, 112, 3)\n",
    "        print('Configuration 10 is selected.')\n",
    "    elif config_selected == 'config11': \n",
    "        model = config11(7, 112, 3)\n",
    "        print('Configuration 11 is selected.')\n",
    "    elif config_selected == 'config12': \n",
    "        model = config12(7, 112, 3)\n",
    "        print('Configuration 12 is selected.')\n",
    "    else: \n",
    "        raise NotImplementedError\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "    # Move model to GPU\n",
    "    model = model.to(device)\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "    opt = optim.AdamW(model.parameters(), lr=0.005)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5, min_lr=0.00000001, verbose=True) \n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "    # print('parameters')\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.requires_grad:\n",
    "    #         print (name, param.data)\n",
    "    # print('----------------')\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "    # for plotting\n",
    "    learning_curve_train = []\n",
    "    learning_curve_val = []\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "    # for early stopping\n",
    "    patience = 0\n",
    "# ------------------------------------------------------------------------------------------------------------------    \n",
    "    # MODIFICATION #2 Chossing the path to save the trained model\n",
    "    if dataset_name == 'dataset_1':\n",
    "        file_path = \"Results_1/\"\n",
    "    else: \n",
    "        file_path = \"Results_2/\"\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    PATH = file_path + config_selected + '.pt'\n",
    "    print(PATH)    \n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "    learn_value_train = 0 \n",
    "    learn_value_validation = 0\n",
    "    # train\n",
    "    for epoch in range(15000):\n",
    "\n",
    "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "        print(lr)\n",
    "     \n",
    "        total_loss = 0\n",
    "        total_len = 0\n",
    "\n",
    "        model.train()\n",
    " \n",
    "        for batch in loader:\n",
    "\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            pred = model(batch)\n",
    "            label = batch.y         \n",
    "            loss = model.loss(pred, label)\n",
    "            loss = loss/ len(batch.y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            # total_loss += loss.item() # if loss isn't being averaged\n",
    "            total_loss += loss.item() * len(batch.y) # if loss is being averaged\n",
    "            total_len += len(label)\n",
    "\n",
    "        total_loss /= total_len   #train loss\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "        # Validation\n",
    "        val_loss = val(validation_loader, model)\n",
    "        learning_curve_train.append(total_loss)\n",
    "        learning_curve_val.append(val_loss)\n",
    "        print(\"Epoch {}. Train Loss: {:.16f}. Validation Loss: {:.16f}\".format(epoch, total_loss, val_loss))\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "        scheduler.step(val_loss)\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "        # Saving model and early stopping\n",
    "        if epoch != 0:\n",
    "            stop = early_stopping(learning_curve_val, current_min)\n",
    "            if stop == False:\n",
    "                current_min = learning_curve_val[-1]\n",
    "                torch.save(model.state_dict(), PATH.format(epoch))                \n",
    "                patience = 0\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "                print(patience)                \n",
    "                if patience == 15:\n",
    "                    break\n",
    "        else:\n",
    "            current_min = learning_curve_val[0]\n",
    "# ------------------------------------------------------------------------------\n",
    "    # MODIFICATION #3\n",
    "    if config_selected == 'config1':\n",
    "        final_model = config1(7, 112, 3)\n",
    "        print('Configuration 1 best state loading...')\n",
    "    elif config_selected == 'config2':  \n",
    "        final_model = config2(7, 112, 3)\n",
    "        print('Configuration 2 best state loading...')\n",
    "    elif config_selected == 'config3':   \n",
    "        final_model = config3(7, 112, 3)\n",
    "        print('Configuration 3 best state loading...')\n",
    "    elif config_selected == 'config4':   \n",
    "        final_model = config4(7, 112, 3)\n",
    "        print('Configuration 4 best state loading...')\n",
    "    elif config_selected == 'config5':  \n",
    "        final_model = config5(7, 112, 3) \n",
    "        print('Configuration 5 best state loading...')\n",
    "    elif config_selected == 'config6': \n",
    "        final_model = config6(7, 112, 3) \n",
    "        print('Configuration 6 best state loading...')\n",
    "    elif config_selected == 'config7': \n",
    "        final_model = config7(7, 112, 3)\n",
    "        print('Configuration 7 best state loading...')\n",
    "    elif config_selected == 'config8':  \n",
    "        final_model = config8(7, 112, 3) \n",
    "        print('Configuration 8 best state loading...')\n",
    "    elif config_selected == 'config9': \n",
    "        final_model = config9(7, 112, 3)\n",
    "        print('Configuration 9 best state loading...')\n",
    "    elif config_selected == 'config10': \n",
    "        final_model = config10(7, 112, 3)\n",
    "        print('Configuration 10 best state loading...')\n",
    "    elif config_selected == 'config11': \n",
    "        final_model = config11(7, 112, 3)\n",
    "        print('Configuration 11 best state loading...')\n",
    "    elif config_selected == 'config12': \n",
    "        final_model = config12(7, 112, 3)\n",
    "        print('Configuration 12 best state loading...')\n",
    "    else: \n",
    "        raise ValueError('The selected configuration does not exist.')\n",
    "    # --------------------------------------------------------------------------\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    final_model.load_state_dict(torch.load(PATH))\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # Final model to GPU\n",
    "    final_model = final_model.to(device)\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    lowest_val_loss = val(validation_loader, final_model)\n",
    "    test_loss = test(test_loader, final_model)\n",
    "\n",
    "    print(\"Validation Loss: {:.16f}. Test Loss: {:.16f}\".format(lowest_val_loss, test_loss))\n",
    "    print('---------------')\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "    for j in range(len(learning_curve_train)):\n",
    "        learn_value_train = learning_curve_train[j]\n",
    "        learn_value_validation = learning_curve_val[j]\n",
    "        print(\"{:.16f} {:.16f}\".format(learn_value_train, learn_value_validation))\n",
    "\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOBmluPm-fFL"
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRUxp9PPznWd"
   },
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "# Validation \n",
    "\n",
    "def val(loader, model):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    error = 0\n",
    "    total_loss = 0\n",
    "    total_length = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "\n",
    "            batch = batch.to(device)\n",
    "        \n",
    "            pred = model(batch)\n",
    "            label = batch.y \n",
    "            # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     \n",
    "            # error = F.mse_loss(pred, label) # MSE\n",
    "            # total_loss += error.item() * len(label) #MSE\n",
    "            # ------------------------------------------------------------------\n",
    "            # total_loss += (pred - label).abs().sum().item()  #MAE\n",
    "            # ------------------------------------------------------------------\n",
    "            total_loss += (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum().item()  # MAE for magnitude\n",
    "            # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  \n",
    "            total_length += len(label)\n",
    "\n",
    "    total_loss /= total_length\n",
    "\n",
    "    return total_loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bs7x1OwM-mcZ"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T77p51zuOucB"
   },
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "# Testing \n",
    "\n",
    "def test(loader, model):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    error = 0\n",
    "    total_loss = 0\n",
    "    total_length = 0\n",
    "         \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data in loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "\n",
    "            pred = model(data)\n",
    "            label = data.y    \n",
    "            # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "            # error = F.mse_loss(pred, label) # MSE\n",
    "            # total_loss += error.item() * len(label) #MSE\n",
    "            # ------------------------------------------------------------------\n",
    "            # total_loss += (pred - label).abs().sum().item()  #MAE\n",
    "            # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "            total_loss += (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum().item()  # MAE for magnitude\n",
    "            # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
    "            total_length += len(label)\n",
    "\n",
    "    total_loss /= total_length \n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3uGgN0gnrB4"
   },
   "source": [
    "#Loading Data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CzVVbPZ95j5S"
   },
   "outputs": [],
   "source": [
    "def get_data(pickled_file_path, dataset):\n",
    "    with open(pickled_file_path, 'rb') as f:\n",
    "        dataset_partial = torch.load(f)\n",
    "\n",
    "        for i, data in enumerate(dataset_partial):\n",
    "            feature = data.x\n",
    "            edge_index = data.edge_index\n",
    "            \n",
    "            # print('---------------')\n",
    "            # print(edge_index)\n",
    "            # print(max(edge_index[0,:]))\n",
    "            # print(max(edge_index[1,:]))\n",
    "            # print('---------------')\n",
    "\n",
    "            edge_values = data.edge_attr\n",
    "            pos = data.pos\n",
    "            y = data.y\n",
    "\n",
    "            # create the data object\n",
    "            data_obj = Data(x=feature, edge_index=edge_index, edge_attr=edge_values, pos=pos, y=y)\n",
    "            dataset.append(data_obj)\n",
    "      \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-vx_OiAwUqj"
   },
   "outputs": [],
   "source": [
    "def load_data(dataset_name):\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    print(dataset_name + ' is being loaded...' )\n",
    "\n",
    "    dataset = get_data(dataset_name + '_pickle/' + dataset_name + '_a_raw.pickle', dataset)\n",
    "    print('1/11 loaded.')\n",
    "    dataset = get_data(dataset_name + '_pickle/' + dataset_name + '_b_raw.pickle', dataset)\n",
    "    print('2/11 loaded.')\n",
    "    dataset = get_data(dataset_name + '_pickle/' + dataset_name + '_c_raw.pickle', dataset)\n",
    "    print('3/11 loaded.')\n",
    "    dataset = get_data(dataset_name + '_pickle/' + dataset_name + '_d_raw.pickle', dataset)\n",
    "    print('4/11 loaded.')\n",
    "    dataset = get_data(dataset_name + '_pickle/' + dataset_name + '_e_raw.pickle', dataset)\n",
    "    print('5/11 loaded.')\n",
    "    dataset = get_data(dataset_name + '_pickle/' + dataset_name + '_f_raw.pickle', dataset)\n",
    "    print('6/11 loaded.')\n",
    "    dataset = get_data(dataset_name + '_pickle/' + dataset_name + '_g_raw.pickle', dataset)\n",
    "    print('7/11 loaded.')\n",
    "    dataset = get_data(dataset_name + '_pickle/' + dataset_name + '_h_raw.pickle', dataset)\n",
    "    print('8/11 loaded.')\n",
    "    dataset = get_data(dataset_name + '_pickle/' + dataset_name + '_i_raw.pickle', dataset)\n",
    "    print('9/11 loaded.')\n",
    "    dataset = get_data(dataset_name + '_pickle/' + dataset_name + '_j_raw.pickle', dataset)\n",
    "    print('10/11 loaded.')\n",
    "    dataset = get_data(dataset_name + '_pickle/' + dataset_name + '_k_raw.pickle', dataset)\n",
    "    print('11/11 loaded.')\n",
    "\n",
    "    print(len(dataset))\n",
    "    print('Datasets have been concatenated.')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYV5QRDtLHf-"
   },
   "source": [
    "#Feature Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIYxF0SC5tTN"
   },
   "outputs": [],
   "source": [
    "# Original Features:\n",
    "# Physiacal Property | Fx | Fy | Fz\n",
    "# New Features: \n",
    "# ------------------------------------------------------\n",
    "# Physical Property | Fx | Fy | Fz | ro | phi | theta\n",
    "# ro    = sqrt(Fx^2 + Fy^2 + Fz^2)\n",
    "# phi   = cos^-1(Fz / ro)\n",
    "# theta = sin^-1(Fy/ ro * sin(phi))\n",
    "# ------------------------------------------------------\n",
    "\n",
    "def add_new_features(dataset):\n",
    "\n",
    "    len_dataset = len(dataset)\n",
    "\n",
    "    for i, data in enumerate(dataset):\n",
    "\n",
    "        ro = torch.sqrt((data.x[:,1]**2) + (data.x[:,2]**2)+ (data.x[:,3]**2)).unsqueeze(-1)\n",
    "        phi = torch.acos(torch.div(data.x[:,3].unsqueeze(-1), ro))\n",
    "        theta = torch.asin(torch.div(data.x[:,2].unsqueeze(-1), torch.mul(ro, torch.sin(phi))))\n",
    "        data.x = torch.cat((data.x, ro, phi, theta), dim=1)\n",
    "        data.x = torch.nan_to_num(data.x)\n",
    "        \n",
    "        print(data.x.shape)\n",
    "        print(str(i+1)+ '/' +str(len_dataset)) \n",
    "    \n",
    "    print('New features have been added.')\n",
    "    return dataset\n",
    "\n",
    "def mean_and_std_calc(dataset):\n",
    "\n",
    "    len_dataset = len(dataset)\n",
    "    \n",
    "    feature = torch.empty(1,1)\n",
    "    i = 0\n",
    "\n",
    "    for i,data in enumerate(dataset):\n",
    "        if i == 0:\n",
    "            feature = data.x\n",
    "        else:\n",
    "            feature = torch.cat((feature, data.x), 0)\n",
    "        i = i + 1\n",
    "        \n",
    "        print(str(i) + '/' + str(len_dataset))\n",
    "        print(feature.shape)\n",
    "\n",
    "    mean_val = torch.mean(feature, dim=0, keepdim=True)\n",
    "    std_val = torch.std(feature, dim=0, keepdim=True)\n",
    "    \n",
    "    print(mean_val)\n",
    "    print(std_val)\n",
    "    \n",
    "    return mean_val, std_val\n",
    "\n",
    "def data_normalize(dataset):\n",
    "\n",
    "    len_dataset = len(dataset)\n",
    "\n",
    "    mean_val, std_val = mean_and_std_calc(dataset)\n",
    "\n",
    "    for i,data in enumerate(dataset):\n",
    "        data.x[:,1:] = (data.x[:,1:]-mean_val[:,1:])/std_val[:,1:]\n",
    "        # data.x[:,:] = (data.x[:,:]-mean_val[:,:])/std_val[:,:]\n",
    "        print(str(i+1) + '' + str(len_dataset))\n",
    "    \n",
    "    print('Data has been normalized.')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMm1oItM3H4u"
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(dataset):\n",
    "\n",
    "    dataset = add_new_features(dataset)\n",
    "    dataset = data_normalize(dataset)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_YRk0KM-9iX"
   },
   "source": [
    "# Final Run for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCcHJHXB1bj-"
   },
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('CUDA availability:', torch.cuda.is_available())\n",
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# ------------------------------------------------------------------------------\n",
    "# Specifying the dataset\n",
    "# dataset_name = 'dataset_1'\n",
    "dataset_name = 'dataset_2'\n",
    "# ----------------------------------------------------\n",
    "# Load data\n",
    "dataset = load_data(dataset_name)\n",
    "# ----------------------------------------------------\n",
    "# Preprocess data\n",
    "dataset = data_preprocessing(dataset)\n",
    "# # ----------------------------------------------------\n",
    "random.Random(1).shuffle(dataset)\n",
    "print('Pytorch Geometric dataset has been shuffeled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zezM3XsFm9xH"
   },
   "outputs": [],
   "source": [
    "# ----- Final Run ------\n",
    "\n",
    "# config_selected = 'config1'     # \n",
    "# config_selected = 'config2'     # done\n",
    "# config_selected = 'config3'     # \n",
    "# config_selected = 'config4'     # \n",
    "# config_selected = 'config5'     # \n",
    "# config_selected = 'config6'     # \n",
    "# config_selected = 'config7'     # \n",
    "# config_selected = 'config8'     # \n",
    "# config_selected = 'config9'     # \n",
    "# config_selected = 'config10'    # \n",
    "# config_selected = 'config11'    # \n",
    "# config_selected = 'config12'    # \n",
    "\n",
    "model = train(dataset, writer, dataset_name, config_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBzdaJLO_H3q"
   },
   "source": [
    "# Reproducing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Blzk9FmGnQq4"
   },
   "source": [
    "##Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpJEVwPA0Sty"
   },
   "outputs": [],
   "source": [
    "def val_reproduce(loader, model):\n",
    "    \n",
    "    model.eval()\n",
    "    error = 0\n",
    "    total_loss = 0\n",
    "    total_length = 0\n",
    "\n",
    "    actual = torch.empty(1,1)\n",
    "    prediction = torch.empty(1,1)\n",
    "    i = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "\n",
    "            batch = batch.to(device)\n",
    "        \n",
    "            pred = model(batch)\n",
    "            label = batch.y \n",
    "            # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   \n",
    "            # to save prediction and actual labels\n",
    "            if i == 0:\n",
    "                prediction = pred \n",
    "                actual = label\n",
    "                i = i +1\n",
    "            else:\n",
    "                prediction = torch.cat((prediction, pred), 0)\n",
    "                actual = torch.cat((actual, label), 0)\n",
    "                i = i +1\n",
    "            # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~      \n",
    "            # error = F.mse_loss(pred, label) # MSE\n",
    "            # total_loss += error.item() * len(label) #MSE\n",
    "            # ------------------------------------------------------------------\n",
    "            # total_loss += (pred - label).abs().sum().item()  #MAE\n",
    "            # ------------------------------------------------------------------\n",
    "            total_loss += (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum().item()  # MAE for magnitude\n",
    "            # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  \n",
    "            total_length += len(label)\n",
    "\n",
    "    total_loss /= total_length\n",
    "\n",
    "    return total_loss, prediction, actual  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmTTOf0TIczy"
   },
   "outputs": [],
   "source": [
    "def test_reproduce(loader, model):\n",
    "\n",
    "    model.eval()\n",
    "    error = 0\n",
    "    total_loss = 0\n",
    "    total_length = 0\n",
    "\n",
    "    actual = torch.empty(1,1)\n",
    "    prediction = torch.empty(1,1)\n",
    "    i = 0\n",
    "         \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            pred = model(data)\n",
    "            label = data.y  \n",
    "            # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "            # to save prediction and actual labels\n",
    "            if i == 0:\n",
    "                prediction = pred \n",
    "                actual = label\n",
    "                i = i +1\n",
    "            else:\n",
    "                prediction = torch.cat((prediction, pred), 0)\n",
    "                actual = torch.cat((actual, label), 0)\n",
    "                i = i +1\n",
    "            # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "            # error = F.mse_loss(pred, label) # MSE\n",
    "            # total_loss += error.item() * len(label) #MSE\n",
    "            # ------------------------------------------------------------------\n",
    "            # total_loss += (pred - label).abs().sum().item()  #MAE\n",
    "            # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "            total_loss += (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))).sum().item()  # MAE for magnitude\n",
    "            # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
    "            total_length += len(label)\n",
    "\n",
    "    total_loss /= total_length \n",
    "\n",
    "    return total_loss, prediction, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSc0US1Vcrgq"
   },
   "outputs": [],
   "source": [
    "def max_magnitude_error(loader, model):\n",
    "\n",
    "    model.eval()\n",
    "    error = 0\n",
    "    max_errors = []\n",
    "    running_time = []\n",
    "    max_displacement = []\n",
    "         \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            \n",
    "            t0 = time.time()\n",
    "            pred = model(data)\n",
    "            label = data.y  \n",
    "            t1 = time.time()\n",
    "            total = t1-t0\n",
    "\n",
    "            running_time.append(total)\n",
    "\n",
    "            loss = (torch.sqrt(((pred[:,0] - label[:,0])**2).unsqueeze(-1) + ((pred[:,1] - label[:,1])**2).unsqueeze(-1) + ((pred[:,2] - label[:,2])**2).unsqueeze(-1))) # MAE for magnitude\n",
    "\n",
    "            max_loss = max(loss).item()\n",
    "            print(max_loss)\n",
    "            max_errors.append(max_loss)\n",
    "\n",
    "            displacement = torch.sqrt((label[:,0]**2).unsqueeze(-1) + (label[:,1]**2).unsqueeze(-1) + (label[:,2]**2).unsqueeze(-1))\n",
    "            max_displacement.append(max(displacement).item())\n",
    "\n",
    "    return max_displacement, max_errors, running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UuH0ZzYdrWTh"
   },
   "outputs": [],
   "source": [
    "def reproduce(dataset, writer, config_selected, save, mean_mag_results, max_error_results):\n",
    "\n",
    "    data_size = len(dataset)\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    if mean_mag_results == 1 and max_error_results == 0:\n",
    "        validation_loader = DataLoader(dataset[int(data_size * 0.7): int(data_size * 0.9)], batch_size=8, shuffle=False)\n",
    "        test_loader = DataLoader(dataset[int(data_size * 0.9):], batch_size=8, shuffle=False)\n",
    "    else:\n",
    "        validation_loader = DataLoader(dataset[int(data_size * 0.7): int(data_size * 0.9)], batch_size=1, shuffle=False)\n",
    "        test_loader = DataLoader(dataset[int(data_size * 0.9):], batch_size=1, shuffle=False)\n",
    "    # ------------------------------------------------------------------------------------------------------------------\n",
    "    # Select the path to the file which holds the final model\n",
    "    if dataset_name == 'dataset_1':\n",
    "        file_path = \"Results_1/\"\n",
    "    else:\n",
    "        file_path = \"Results_2/\"\n",
    "    # --------------------------------------------\n",
    "    PATH = file_path + config_selected + '.pt'\n",
    "    print(PATH)\n",
    "    # --------------------------------------------\n",
    "    # Initialize the model\n",
    "    if config_selected == 'config1': \n",
    "        final_model = config1(7, 112, 3)\n",
    "        print('Configuration 1 has been selected.')\n",
    "    elif config_selected == 'config2':  \n",
    "        final_model = config2(7, 112, 3)\n",
    "        print('Configuration 2 has been selected.')\n",
    "    elif config_selected == 'config3':\n",
    "        final_model = config3(7, 112, 3) \n",
    "        print('Configuration 3 has been selected.')   \n",
    "    elif config_selected == 'config4':\n",
    "        final_model = config4(7, 112, 3) \n",
    "        print('Configuration 4 has been selected.')  \n",
    "    elif config_selected == 'config5':\n",
    "        final_model = config5(7, 112, 3)\n",
    "        print('Configuration 5 has been selected.')\n",
    "    elif config_selected == 'config6': \n",
    "        final_model = config6(7, 112, 3)\n",
    "        print('Configuration 6 has been selected.')\n",
    "    elif config_selected == 'config7': \n",
    "        final_model = config7(7, 112, 3)\n",
    "        print('Configuration 7 has been selected.')\n",
    "    elif config_selected == 'config8':    \n",
    "        final_model = config8(7, 112, 3)\n",
    "        print('Configuration 8 has been selected.')\n",
    "    elif config_selected == 'config9':        \n",
    "        final_model = config9(7, 112, 3)  \n",
    "        print('Configuration 9 has been selected.')  \n",
    "    elif config_selected == 'config10':    \n",
    "        final_model = config10(7, 112, 3)\n",
    "        print('Configuration 10 has been selected.')   \n",
    "    elif config_selected == 'config11':    \n",
    "        final_model = config11(7, 112, 3) \n",
    "        print('Configuration 11 has been selected.')  \n",
    "    elif config_selected == 'config12':    \n",
    "        final_model = config12(7, 112, 3)\n",
    "        print('Configuration 12 has been selected.')\n",
    "    else:  \n",
    "        raise NotImplementedError            \n",
    "    # ----------------------------------------------\n",
    "    # Load the model\n",
    "    final_model.load_state_dict(torch.load(PATH))\n",
    "    # ----------------------------------------------\n",
    "    # Final model to GPU\n",
    "    final_model = final_model.to(device)\n",
    "    # ----------------------------------------------\n",
    "    # ######################################################################################################\n",
    "    # Reproducing the mean of maximum errors in magnitude and runtime results\n",
    "    if max_error_results == 1:\n",
    "\n",
    "        max_displacement, max_error_test, running_time = max_magnitude_error(test_loader, final_model)\n",
    "\n",
    "        max_maximum_displacement = max(max_displacement)\n",
    "        print(max_maximum_displacement)\n",
    "        mean_maximum_displacement = statistics.mean(max_displacement)\n",
    "        print(mean_maximum_displacement)\n",
    "        std_max_displacement = statistics.stdev(max_displacement)\n",
    "        print(std_max_displacement)\n",
    "        print(\"Maximum displacement in the test set: {:.4f}. Average maximum displacement {:.4f} +/- {:.4f}\".format(max_maximum_displacement, mean_maximum_displacement, std_max_displacement))\n",
    "\n",
    "        mean_maximum_test_loss = statistics.mean(max_error_test)\n",
    "        std_maximum_test_loss = statistics.stdev(max_error_test)\n",
    "        print(\"Average maximum magnitude error: {:.4f} +/- {:.4f}\".format(mean_maximum_test_loss, std_maximum_test_loss))\n",
    "\n",
    "        mean_time = statistics.mean(running_time)\n",
    "        std_time = statistics.stdev(running_time)\n",
    "        print(\"Average running time: {:.4f} +/- {:.4f}\".format(mean_time, std_time))\n",
    "\n",
    "    # ######################################################################################################\n",
    "    # Reproducing the results in Table 1 and Table 2\n",
    "    if mean_mag_results == 1:\n",
    "    \n",
    "        if save == 0:\n",
    "            lowest_val_loss = val(validation_loader, final_model)\n",
    "            test_mse = test(test_loader, final_model)\n",
    "            print(\"Validation Loss: {:.16f} Test Loss: {:.16f}\".format(lowest_val_loss, test_mse))\n",
    "        else:\n",
    "            lowest_val_loss, prediction_val, actual_val = val_reproduce(validation_loader, final_model)\n",
    "            test_mse, prediction_test, actual_test = test_reproduce(test_loader, final_model)\n",
    "            print(\"Validation Loss: {:.16f} Test Loss: {:.16f}\".format(lowest_val_loss, test_mse))\n",
    "\n",
    "            # -----------------------------------------------------------------------------------------------\n",
    "            # Saving the results for further analysis \n",
    "            print('Saving the results...')\n",
    "            \n",
    "            # Validation set \n",
    "            prediction_val = prediction_val.cpu()\n",
    "            actual_val = actual_val.cpu()\n",
    "            prediction_val = prediction_val.numpy()\n",
    "            prediction_val_df = pd.DataFrame(prediction_val)\n",
    "            # ------------------------------------------------------------------------------------------------\n",
    "            prediction_val_df.to_csv(file_path + 'csv/val/prediction_' + config_selected + '.csv')\n",
    "            # ------------------------------------------------------------------------------------------------\n",
    "            actual_val = actual_val.numpy()\n",
    "            actual_val_df = pd.DataFrame(actual_val)\n",
    "            # ------------------------------------------------------------------------------------------------\n",
    "            actual_val_df.to_csv(file_path + 'csv/val/actual_' + config_selected + '.csv')    \n",
    "            # ------------------------------------------------------------------------------------------------\n",
    "            \n",
    "            # Test set \n",
    "            prediction_test = prediction_test.cpu()\n",
    "            actual_test = actual_test.cpu()\n",
    "            prediction_test = prediction_test.numpy()\n",
    "            prediction_test_df = pd.DataFrame(prediction_test)\n",
    "            # ------------------------------------------------------------------------------------------------\n",
    "            prediction_test_df.to_csv(file_path + 'csv/test/prediction_' + config_selected + '.csv')        \n",
    "            # ------------------------------------------------------------------------------------------------\n",
    "            actual_test = actual_test.numpy()\n",
    "            actual_test_df = pd.DataFrame(actual_test)\n",
    "            # ------------------------------------------------------------------------------------------------    \n",
    "            actual_test_df.to_csv(file_path + 'csv/test/actual_' + config_selected + '.csv')                \n",
    "            # ------------------------------------------------------------------------------------------------\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj-a2pEinVNi"
   },
   "source": [
    "##Final Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "doE0yWA9ICs3"
   },
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('CUDA availability:', torch.cuda.is_available())\n",
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# ------------------------------------------------------------------------------\n",
    "# Specifying the dataset\n",
    "# dataset_name = 'dataset_1'\n",
    "dataset_name = 'dataset_2'\n",
    "# ----------------------------------------------------\n",
    "# Load data\n",
    "dataset = load_data(dataset_name)\n",
    "# ----------------------------------------------------\n",
    "# Preprocess data\n",
    "dataset = data_preprocessing(dataset)\n",
    "# # ----------------------------------------------------\n",
    "random.Random(1).shuffle(dataset)\n",
    "print('Pytorch Geometric dataset has been shuffeled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "863yeBqTyeuy"
   },
   "outputs": [],
   "source": [
    "# If save is equal to 1, the prediction and actual values will be saved for \n",
    "# further result processing.\n",
    "save = 0 \n",
    "mean_mag_results = 0\n",
    "max_error_results = 1\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# Please note:\n",
    "# Best performing model for dataset 1 is config 9\n",
    "# Best performing model for dataset 2 is config 3\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# Select configuration\n",
    "\n",
    "# reproduce(dataset, writer, 'config1', save, mean_mag_results, max_error_results)\n",
    "# reproduce(dataset, writer, 'config2', save, mean_mag_results, max_error_results)\n",
    "# reproduce(dataset, writer, 'config3', save, mean_mag_results, max_error_results) # best performance dataset 2\n",
    "# reproduce(dataset, writer, 'config4', save, mean_mag_results, max_error_results)\n",
    "# reproduce(dataset, writer, 'config5', save, mean_mag_results, max_error_results)\n",
    "# reproduce(dataset, writer, 'config6', save, mean_mag_results, max_error_results)\n",
    "# reproduce(dataset, writer, 'config7', save, mean_mag_results, max_error_results)\n",
    "# reproduce(dataset, writer, 'config8', save, mean_mag_results, max_error_results)\n",
    "reproduce(dataset, writer, 'config9', save, mean_mag_results, max_error_results) # best performance dataset 1\n",
    "# reproduce(dataset, writer, 'config10', save, mean_mag_results, max_error_results)\n",
    "# reproduce(dataset, writer, 'config11', save, mean_mag_results, max_error_results)\n",
    "# reproduce(dataset, writer, 'config12', save, mean_mag_results, max_error_results)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of GNN_Brain_V24.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "pkf9vx6lXom4",
    "D4O_TNMc91_d",
    "GFEf8O_sAR9y",
    "veYEEy6_3rox",
    "DSri18MsCs42",
    "5Rat5cGP0_29",
    "LTeiUT57usRK",
    "SDbu1I22uwGW",
    "Pd-rZrCb6ju0",
    "GMZmrFkWoGnk",
    "_8lngNjPu1AP",
    "72eIcafFxDiJ",
    "GH-VDv8FBc4d",
    "Bs7x1OwM-mcZ",
    "vtPIP85e-suR",
    "TQ0VfdE75Ob2",
    "WJHPoKa95WuY",
    "F74tpKU7G3Rk",
    "xBzdaJLO_H3q"
   ],
   "toc_visible": true,
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
